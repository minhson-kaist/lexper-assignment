{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c03b4d",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0afa27b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T06:44:13.966521Z",
     "start_time": "2022-01-16T06:44:13.962844Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70a830c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T06:40:34.430710Z",
     "start_time": "2022-01-16T06:39:46.491568Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471b2abcf1c34660bf751bfb646b7534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152b833c51f04002886ebef54c470fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e0920520654b9980ce03c6bfaea9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7701fad16a45858b3a50c517b399d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cae0bf42e741ca9f1eb10f8309159f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a168613",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T06:49:38.692386Z",
     "start_time": "2022-01-16T06:49:38.680774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c5a1c",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9522b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T06:51:47.681894Z",
     "start_time": "2022-01-16T06:51:47.476861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CoLA dataset...\n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print('Downloading CoLA dataset...')\n",
    "\n",
    "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "\n",
    "if not os.path.exists('./cola_data.zip'):\n",
    "    wget.download(url, './cola_data.zip')\n",
    "\n",
    "print('Download completed.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8e1c8dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T06:52:00.476660Z",
     "start_time": "2022-01-16T06:51:52.260570Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  cola_data.zip\n",
      "replace cola_public/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./cola_data/'):\n",
    "    !unzip cola_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1be1d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:04:02.498733Z",
     "start_time": "2022-01-16T07:04:02.470932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>m_02</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Although in came Aunt Norris, Fanny continued ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Those books slide across the table easily.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am not certain about whether he will go or not.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>r-67</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Harry thinks so, although no one else thinks S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I spoke to him about the war yesterday, that g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>cj99</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm going out, wherever that hurricane might be.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>sgww85</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I consider that a rude remark and in very bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>c_13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bruce loved and Kelly hated phonology class.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mark's single mindedness terrified me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>ks08</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>They reputed him to be a good scholar.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sent_source  label label_notes  \\\n",
       "6781        m_02      0           *   \n",
       "2681        l-93      1         NaN   \n",
       "4813        ks08      1         NaN   \n",
       "1592        r-67      0           *   \n",
       "1865        r-67      1         NaN   \n",
       "181         cj99      1         NaN   \n",
       "6997      sgww85      1         NaN   \n",
       "5706        c_13      1         NaN   \n",
       "2381        l-93      1         NaN   \n",
       "4660        ks08      0           *   \n",
       "\n",
       "                                               sentence  \n",
       "6781  Although in came Aunt Norris, Fanny continued ...  \n",
       "2681         Those books slide across the table easily.  \n",
       "4813  I am not certain about whether he will go or not.  \n",
       "1592  Harry thinks so, although no one else thinks S...  \n",
       "1865  I spoke to him about the war yesterday, that g...  \n",
       "181    I'm going out, wherever that hurricane might be.  \n",
       "6997  I consider that a rude remark and in very bad ...  \n",
       "5706       Bruce loved and Kelly hated phonology class.  \n",
       "2381             Mark's single mindedness terrified me.  \n",
       "4660             They reputed him to be a good scholar.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sent_source', 'label', 'label_notes', 'sentence'])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0c51a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T14:08:24.812718Z",
     "start_time": "2022-01-16T14:08:24.803047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_source                              clc95\n",
       "label                                            1\n",
       "label_notes                                    NaN\n",
       "sentence           Somebody just left - guess who.\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee871f4",
   "metadata": {},
   "source": [
    "## Pre-process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cceaa",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1368cfe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:04:39.625004Z",
     "start_time": "2022-01-16T07:04:39.621121Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = df.sentence.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd922b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:04:57.640122Z",
     "start_time": "2022-01-16T07:04:54.205620Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(sent,\n",
    "                                         add_special_tokens = True, \n",
    "                                         max_length = 64,\n",
    "                                         pad_to_max_length = True,\n",
    "                                         return_attention_mask = True, \n",
    "                                         return_tensors = 'pt')\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b0becc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:05:53.666920Z",
     "start_time": "2022-01-16T07:05:53.661203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7,695 training samples\n",
      "    856 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Set the ratio of train-val data to 9:1\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>7,} training samples'.format(train_size))\n",
    "print('{:>7,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c8c7ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:08:11.833795Z",
     "start_time": "2022-01-16T07:08:11.829234Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# create dataloader for train and validation dataset\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c2723",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2089e97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:09:20.679246Z",
     "start_time": "2022-01-16T07:09:09.693985Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b58a7fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:10:02.704705Z",
     "start_time": "2022-01-16T07:10:02.701188Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 3\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb33f7",
   "metadata": {},
   "source": [
    "### Utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a4a48b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:10:49.154132Z",
     "start_time": "2022-01-16T07:10:49.150093Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff0ba9",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b89faa5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T07:11:49.930004Z",
     "start_time": "2022-01-16T07:11:49.925352Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    \"\"\"\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\"\"\"\n",
    "    \n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2604a965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:25:27.358085Z",
     "start_time": "2022-01-16T07:16:47.798831Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Epoch 1 / 3 =======\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:06,  6.25s/it]\u001b[A\n",
      "2it [00:11,  5.90s/it]\u001b[A\n",
      "3it [00:17,  5.58s/it]\u001b[A\n",
      "4it [00:23,  5.79s/it]\u001b[A\n",
      "5it [00:28,  5.73s/it]\u001b[A\n",
      "6it [00:34,  5.61s/it]\u001b[A\n",
      "7it [00:39,  5.58s/it]\u001b[A\n",
      "8it [00:45,  5.61s/it]\u001b[A\n",
      "9it [00:50,  5.46s/it]\u001b[A\n",
      "10it [00:56,  5.55s/it]\u001b[A\n",
      "11it [01:01,  5.50s/it]\u001b[A\n",
      "12it [01:06,  5.38s/it]\u001b[A\n",
      "13it [01:12,  5.34s/it]\u001b[A\n",
      "14it [01:17,  5.32s/it]\u001b[A\n",
      "15it [01:22,  5.38s/it]\u001b[A\n",
      "16it [01:28,  5.44s/it]\u001b[A\n",
      "17it [01:33,  5.39s/it]\u001b[A\n",
      "18it [01:39,  5.39s/it]\u001b[A\n",
      "19it [01:44,  5.40s/it]\u001b[A\n",
      "20it [01:49,  5.30s/it]\u001b[A\n",
      "21it [01:55,  5.50s/it]\u001b[A\n",
      "22it [02:00,  5.47s/it]\u001b[A\n",
      "23it [02:06,  5.38s/it]\u001b[A\n",
      "24it [02:11,  5.35s/it]\u001b[A\n",
      "25it [02:16,  5.42s/it]\u001b[A\n",
      "26it [02:22,  5.51s/it]\u001b[A\n",
      "27it [02:28,  5.54s/it]\u001b[A\n",
      "28it [02:33,  5.42s/it]\u001b[A\n",
      "29it [02:38,  5.38s/it]\u001b[A\n",
      "30it [02:43,  5.31s/it]\u001b[A\n",
      "31it [02:49,  5.33s/it]\u001b[A\n",
      "32it [02:55,  5.55s/it]\u001b[A\n",
      "33it [03:00,  5.55s/it]\u001b[A\n",
      "34it [03:06,  5.48s/it]\u001b[A\n",
      "35it [03:11,  5.44s/it]\u001b[A\n",
      "36it [03:16,  5.43s/it]\u001b[A\n",
      "37it [03:22,  5.46s/it]\u001b[A\n",
      "38it [03:28,  5.60s/it]\u001b[A\n",
      "39it [03:33,  5.61s/it]\u001b[A\n",
      "40it [03:39,  5.58s/it]\u001b[A\n",
      "41it [03:44,  5.50s/it]\u001b[A\n",
      "42it [03:50,  5.46s/it]\u001b[A\n",
      "43it [03:56,  5.65s/it]\u001b[A\n",
      "44it [04:01,  5.61s/it]\u001b[A\n",
      "45it [04:07,  5.60s/it]\u001b[A\n",
      "46it [04:12,  5.55s/it]\u001b[A\n",
      "47it [04:18,  5.50s/it]\u001b[A\n",
      "48it [04:23,  5.54s/it]\u001b[A\n",
      "49it [04:29,  5.55s/it]\u001b[A\n",
      "50it [04:34,  5.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch    50  of    241. Elapsed: 0:04:35.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [04:39,  5.41s/it]\u001b[A\n",
      "52it [04:45,  5.40s/it]\u001b[A\n",
      "53it [04:50,  5.42s/it]\u001b[A\n",
      "54it [04:56,  5.59s/it]\u001b[A\n",
      "55it [05:02,  5.55s/it]\u001b[A\n",
      "56it [05:07,  5.53s/it]\u001b[A\n",
      "57it [05:13,  5.48s/it]\u001b[A\n",
      "58it [05:18,  5.52s/it]\u001b[A\n",
      "59it [05:24,  5.73s/it]\u001b[A\n",
      "60it [05:30,  5.61s/it]\u001b[A\n",
      "61it [05:35,  5.61s/it]\u001b[A\n",
      "62it [05:41,  5.55s/it]\u001b[A\n",
      "63it [05:46,  5.39s/it]\u001b[A\n",
      "64it [05:51,  5.37s/it]\u001b[A\n",
      "65it [05:57,  5.42s/it]\u001b[A\n",
      "66it [06:02,  5.35s/it]\u001b[A\n",
      "67it [06:07,  5.33s/it]\u001b[A\n",
      "68it [06:13,  5.34s/it]\u001b[A\n",
      "69it [06:18,  5.35s/it]\u001b[A\n",
      "70it [06:24,  5.53s/it]\u001b[A\n",
      "71it [06:29,  5.47s/it]\u001b[A\n",
      "72it [06:35,  5.44s/it]\u001b[A\n",
      "73it [06:40,  5.34s/it]\u001b[A\n",
      "74it [06:45,  5.33s/it]\u001b[A\n",
      "75it [06:50,  5.32s/it]\u001b[A\n",
      "76it [06:56,  5.47s/it]\u001b[A\n",
      "77it [07:01,  5.45s/it]\u001b[A\n",
      "78it [07:07,  5.35s/it]\u001b[A\n",
      "79it [07:12,  5.30s/it]\u001b[A\n",
      "80it [07:17,  5.35s/it]\u001b[A\n",
      "81it [07:23,  5.40s/it]\u001b[A\n",
      "82it [07:29,  5.53s/it]\u001b[A\n",
      "83it [07:35,  5.67s/it]\u001b[A\n",
      "84it [07:40,  5.64s/it]\u001b[A\n",
      "85it [07:46,  5.60s/it]\u001b[A\n",
      "86it [07:51,  5.61s/it]\u001b[A\n",
      "87it [07:57,  5.78s/it]\u001b[A\n",
      "88it [08:03,  5.82s/it]\u001b[A\n",
      "89it [08:09,  5.70s/it]\u001b[A\n",
      "90it [08:14,  5.55s/it]\u001b[A\n",
      "91it [08:19,  5.48s/it]\u001b[A\n",
      "92it [08:26,  5.82s/it]\u001b[A\n",
      "93it [08:31,  5.75s/it]\u001b[A\n",
      "94it [08:37,  5.65s/it]\u001b[A\n",
      "95it [08:42,  5.56s/it]\u001b[A\n",
      "96it [08:48,  5.52s/it]\u001b[A\n",
      "97it [08:54,  5.66s/it]\u001b[A\n",
      "98it [08:59,  5.60s/it]\u001b[A\n",
      "99it [09:05,  5.56s/it]\u001b[A\n",
      "100it [09:10,  5.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   100  of    241. Elapsed: 0:09:10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "101it [09:15,  5.37s/it]\u001b[A\n",
      "102it [09:20,  5.32s/it]\u001b[A\n",
      "103it [09:26,  5.47s/it]\u001b[A\n",
      "104it [09:32,  5.49s/it]\u001b[A\n",
      "105it [09:37,  5.43s/it]\u001b[A\n",
      "106it [09:42,  5.42s/it]\u001b[A\n",
      "107it [09:48,  5.42s/it]\u001b[A\n",
      "108it [09:53,  5.53s/it]\u001b[A\n",
      "109it [09:59,  5.45s/it]\u001b[A\n",
      "110it [10:04,  5.38s/it]\u001b[A\n",
      "111it [10:09,  5.40s/it]\u001b[A\n",
      "112it [10:15,  5.37s/it]\u001b[A\n",
      "113it [10:21,  5.57s/it]\u001b[A\n",
      "114it [10:26,  5.63s/it]\u001b[A\n",
      "115it [10:32,  5.59s/it]\u001b[A\n",
      "116it [10:37,  5.49s/it]\u001b[A\n",
      "117it [10:43,  5.49s/it]\u001b[A\n",
      "118it [10:48,  5.40s/it]\u001b[A\n",
      "119it [10:54,  5.47s/it]\u001b[A\n",
      "120it [10:59,  5.40s/it]\u001b[A\n",
      "121it [11:04,  5.41s/it]\u001b[A\n",
      "122it [11:09,  5.34s/it]\u001b[A\n",
      "123it [11:15,  5.32s/it]\u001b[A\n",
      "124it [11:20,  5.28s/it]\u001b[A\n",
      "125it [11:26,  5.45s/it]\u001b[A\n",
      "126it [11:31,  5.39s/it]\u001b[A\n",
      "127it [11:36,  5.33s/it]\u001b[A\n",
      "128it [11:41,  5.31s/it]\u001b[A\n",
      "129it [11:47,  5.30s/it]\u001b[A\n",
      "130it [11:52,  5.40s/it]\u001b[A\n",
      "131it [11:58,  5.40s/it]\u001b[A\n",
      "132it [12:03,  5.41s/it]\u001b[A\n",
      "133it [12:09,  5.48s/it]\u001b[A\n",
      "134it [12:14,  5.50s/it]\u001b[A\n",
      "135it [12:20,  5.48s/it]\u001b[A\n",
      "136it [12:26,  5.59s/it]\u001b[A\n",
      "137it [12:31,  5.51s/it]\u001b[A\n",
      "138it [12:36,  5.43s/it]\u001b[A\n",
      "139it [12:41,  5.39s/it]\u001b[A\n",
      "140it [12:47,  5.42s/it]\u001b[A\n",
      "141it [12:53,  5.50s/it]\u001b[A\n",
      "142it [12:58,  5.44s/it]\u001b[A\n",
      "143it [13:03,  5.37s/it]\u001b[A\n",
      "144it [13:08,  5.30s/it]\u001b[A\n",
      "145it [13:14,  5.33s/it]\u001b[A\n",
      "146it [13:20,  5.63s/it]\u001b[A\n",
      "147it [13:27,  5.89s/it]\u001b[A\n",
      "148it [13:33,  5.98s/it]\u001b[A\n",
      "149it [13:38,  5.85s/it]\u001b[A\n",
      "150it [13:44,  5.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   150  of    241. Elapsed: 0:13:44.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "151it [13:49,  5.64s/it]\u001b[A\n",
      "152it [13:55,  5.76s/it]\u001b[A\n",
      "153it [14:00,  5.56s/it]\u001b[A\n",
      "154it [14:06,  5.51s/it]\u001b[A\n",
      "155it [14:11,  5.49s/it]\u001b[A\n",
      "156it [14:17,  5.57s/it]\u001b[A\n",
      "157it [14:23,  5.66s/it]\u001b[A\n",
      "158it [14:28,  5.67s/it]\u001b[A\n",
      "159it [14:34,  5.75s/it]\u001b[A\n",
      "160it [14:40,  5.80s/it]\u001b[A\n",
      "161it [14:46,  5.66s/it]\u001b[A\n",
      "162it [14:51,  5.67s/it]\u001b[A\n",
      "163it [14:57,  5.69s/it]\u001b[A\n",
      "164it [15:03,  5.63s/it]\u001b[A\n",
      "165it [15:08,  5.49s/it]\u001b[A\n",
      "166it [15:13,  5.41s/it]\u001b[A\n",
      "167it [15:19,  5.61s/it]\u001b[A\n",
      "168it [15:25,  5.78s/it]\u001b[A\n",
      "169it [15:30,  5.62s/it]\u001b[A\n",
      "170it [15:36,  5.55s/it]\u001b[A\n",
      "171it [15:41,  5.50s/it]\u001b[A\n",
      "172it [15:48,  5.83s/it]\u001b[A\n",
      "173it [15:55,  6.11s/it]\u001b[A\n",
      "174it [16:00,  6.01s/it]\u001b[A\n",
      "175it [16:06,  5.83s/it]\u001b[A\n",
      "176it [16:11,  5.66s/it]\u001b[A\n",
      "177it [16:17,  5.64s/it]\u001b[A\n",
      "178it [16:22,  5.68s/it]\u001b[A\n",
      "179it [16:28,  5.66s/it]\u001b[A\n",
      "180it [16:33,  5.54s/it]\u001b[A\n",
      "181it [16:39,  5.50s/it]\u001b[A\n",
      "182it [16:44,  5.45s/it]\u001b[A\n",
      "183it [16:49,  5.38s/it]\u001b[A\n",
      "184it [16:55,  5.53s/it]\u001b[A\n",
      "185it [17:00,  5.49s/it]\u001b[A\n",
      "186it [17:06,  5.42s/it]\u001b[A\n",
      "187it [17:11,  5.34s/it]\u001b[A\n",
      "188it [17:16,  5.36s/it]\u001b[A\n",
      "189it [17:22,  5.42s/it]\u001b[A\n",
      "190it [17:27,  5.49s/it]\u001b[A\n",
      "191it [17:33,  5.48s/it]\u001b[A\n",
      "192it [17:38,  5.41s/it]\u001b[A\n",
      "193it [17:44,  5.44s/it]\u001b[A\n",
      "194it [17:49,  5.36s/it]\u001b[A\n",
      "195it [17:55,  5.52s/it]\u001b[A\n",
      "196it [18:01,  5.70s/it]\u001b[A\n",
      "197it [18:06,  5.66s/it]\u001b[A\n",
      "198it [18:12,  5.51s/it]\u001b[A\n",
      "199it [18:17,  5.52s/it]\u001b[A\n",
      "200it [18:23,  5.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   200  of    241. Elapsed: 0:18:24.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "201it [18:28,  5.54s/it]\u001b[A\n",
      "202it [18:34,  5.49s/it]\u001b[A\n",
      "203it [18:39,  5.38s/it]\u001b[A\n",
      "204it [18:44,  5.40s/it]\u001b[A\n",
      "205it [18:50,  5.40s/it]\u001b[A\n",
      "206it [18:56,  5.53s/it]\u001b[A\n",
      "207it [19:01,  5.42s/it]\u001b[A\n",
      "208it [19:07,  5.63s/it]\u001b[A\n",
      "209it [19:12,  5.61s/it]\u001b[A\n",
      "210it [19:18,  5.64s/it]\u001b[A\n",
      "211it [19:24,  5.71s/it]\u001b[A\n",
      "212it [19:29,  5.64s/it]\u001b[A\n",
      "213it [19:35,  5.49s/it]\u001b[A\n",
      "214it [19:40,  5.40s/it]\u001b[A\n",
      "215it [19:45,  5.41s/it]\u001b[A\n",
      "216it [19:51,  5.41s/it]\u001b[A\n",
      "217it [19:56,  5.52s/it]\u001b[A\n",
      "218it [20:02,  5.58s/it]\u001b[A\n",
      "219it [20:08,  5.60s/it]\u001b[A\n",
      "220it [20:13,  5.58s/it]\u001b[A\n",
      "221it [20:19,  5.70s/it]\u001b[A\n",
      "222it [20:25,  5.82s/it]\u001b[A\n",
      "223it [20:31,  5.66s/it]\u001b[A\n",
      "224it [20:36,  5.56s/it]\u001b[A\n",
      "225it [20:41,  5.47s/it]\u001b[A\n",
      "226it [20:47,  5.47s/it]\u001b[A\n",
      "227it [20:52,  5.52s/it]\u001b[A\n",
      "228it [20:58,  5.55s/it]\u001b[A\n",
      "229it [21:03,  5.44s/it]\u001b[A\n",
      "230it [21:09,  5.51s/it]\u001b[A\n",
      "231it [21:14,  5.47s/it]\u001b[A\n",
      "232it [21:19,  5.39s/it]\u001b[A\n",
      "233it [21:25,  5.52s/it]\u001b[A\n",
      "234it [21:31,  5.56s/it]\u001b[A\n",
      "235it [21:36,  5.51s/it]\u001b[A\n",
      "236it [21:42,  5.51s/it]\u001b[A\n",
      "237it [21:47,  5.45s/it]\u001b[A\n",
      "238it [21:53,  5.49s/it]\u001b[A\n",
      "239it [21:58,  5.46s/it]\u001b[A\n",
      "240it [22:03,  5.36s/it]\u001b[A\n",
      "241it [22:06,  5.50s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training loss: 0.51\n",
      "Training epoch took: 0:22:07\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 1/27 [00:01<00:41,  1.61s/it]\u001b[A\n",
      "  7%|▋         | 2/27 [00:03<00:38,  1.55s/it]\u001b[A\n",
      " 11%|█         | 3/27 [00:04<00:38,  1.60s/it]\u001b[A\n",
      " 15%|█▍        | 4/27 [00:06<00:36,  1.61s/it]\u001b[A\n",
      " 19%|█▊        | 5/27 [00:08<00:36,  1.66s/it]\u001b[A\n",
      " 22%|██▏       | 6/27 [00:09<00:33,  1.60s/it]\u001b[A\n",
      " 26%|██▌       | 7/27 [00:11<00:33,  1.66s/it]\u001b[A\n",
      " 30%|██▉       | 8/27 [00:13<00:31,  1.65s/it]\u001b[A\n",
      " 33%|███▎      | 9/27 [00:14<00:29,  1.65s/it]\u001b[A\n",
      " 37%|███▋      | 10/27 [00:16<00:28,  1.68s/it]\u001b[A\n",
      " 41%|████      | 11/27 [00:18<00:27,  1.70s/it]\u001b[A\n",
      " 44%|████▍     | 12/27 [00:19<00:25,  1.71s/it]\u001b[A\n",
      " 48%|████▊     | 13/27 [00:21<00:23,  1.68s/it]\u001b[A\n",
      " 52%|█████▏    | 14/27 [00:23<00:21,  1.66s/it]\u001b[A\n",
      " 56%|█████▌    | 15/27 [00:24<00:20,  1.67s/it]\u001b[A\n",
      " 59%|█████▉    | 16/27 [00:26<00:17,  1.62s/it]\u001b[A\n",
      " 63%|██████▎   | 17/27 [00:27<00:15,  1.60s/it]\u001b[A\n",
      " 67%|██████▋   | 18/27 [00:29<00:14,  1.59s/it]\u001b[A\n",
      " 70%|███████   | 19/27 [00:31<00:12,  1.60s/it]\u001b[A\n",
      " 74%|███████▍  | 20/27 [00:32<00:11,  1.60s/it]\u001b[A\n",
      " 78%|███████▊  | 21/27 [00:34<00:09,  1.60s/it]\u001b[A\n",
      " 81%|████████▏ | 22/27 [00:35<00:07,  1.59s/it]\u001b[A\n",
      " 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it]\u001b[A\n",
      " 89%|████████▉ | 24/27 [00:39<00:04,  1.65s/it]\u001b[A\n",
      " 93%|█████████▎| 25/27 [00:40<00:03,  1.67s/it]\u001b[A\n",
      " 96%|█████████▋| 26/27 [00:42<00:01,  1.64s/it]\u001b[A\n",
      "100%|██████████| 27/27 [00:43<00:00,  1.62s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [22:50<45:40, 1370.23s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Validation Loss: 0.37\n",
      "Validation took: 0:00:44\n",
      "======= Epoch 2 / 3 =======\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:05,  5.84s/it]\u001b[A\n",
      "2it [00:11,  5.63s/it]\u001b[A\n",
      "3it [00:16,  5.53s/it]\u001b[A\n",
      "4it [00:22,  5.46s/it]\u001b[A\n",
      "5it [00:27,  5.49s/it]\u001b[A\n",
      "6it [00:33,  5.68s/it]\u001b[A\n",
      "7it [00:39,  5.67s/it]\u001b[A\n",
      "8it [00:44,  5.66s/it]\u001b[A\n",
      "9it [00:50,  5.71s/it]\u001b[A\n",
      "10it [00:56,  5.68s/it]\u001b[A\n",
      "11it [01:02,  5.68s/it]\u001b[A\n",
      "12it [01:07,  5.61s/it]\u001b[A\n",
      "13it [01:12,  5.46s/it]\u001b[A\n",
      "14it [01:18,  5.49s/it]\u001b[A\n",
      "15it [01:23,  5.54s/it]\u001b[A\n",
      "16it [01:29,  5.67s/it]\u001b[A\n",
      "17it [01:35,  5.79s/it]\u001b[A\n",
      "18it [01:42,  5.98s/it]\u001b[A\n",
      "19it [01:48,  5.98s/it]\u001b[A\n",
      "20it [01:53,  5.72s/it]\u001b[A\n",
      "21it [01:59,  5.96s/it]\u001b[A\n",
      "22it [02:06,  5.99s/it]\u001b[A\n",
      "23it [02:11,  5.81s/it]\u001b[A\n",
      "24it [02:17,  5.77s/it]\u001b[A\n",
      "25it [02:22,  5.60s/it]\u001b[A\n",
      "26it [02:27,  5.57s/it]\u001b[A\n",
      "27it [02:34,  5.87s/it]\u001b[A\n",
      "28it [02:40,  5.85s/it]\u001b[A\n",
      "29it [02:46,  5.94s/it]\u001b[A\n",
      "30it [02:51,  5.84s/it]\u001b[A\n",
      "31it [02:57,  5.84s/it]\u001b[A\n",
      "32it [03:03,  5.84s/it]\u001b[A\n",
      "33it [03:08,  5.68s/it]\u001b[A\n",
      "34it [03:14,  5.60s/it]\u001b[A\n",
      "35it [03:19,  5.48s/it]\u001b[A\n",
      "36it [03:24,  5.47s/it]\u001b[A\n",
      "37it [03:30,  5.46s/it]\u001b[A\n",
      "38it [03:36,  5.54s/it]\u001b[A\n",
      "39it [03:41,  5.54s/it]\u001b[A\n",
      "40it [03:47,  5.49s/it]\u001b[A\n",
      "41it [03:52,  5.53s/it]\u001b[A\n",
      "42it [03:58,  5.48s/it]\u001b[A\n",
      "43it [04:03,  5.50s/it]\u001b[A\n",
      "44it [04:09,  5.52s/it]\u001b[A\n",
      "45it [04:14,  5.52s/it]\u001b[A\n",
      "46it [04:20,  5.49s/it]\u001b[A\n",
      "47it [04:25,  5.48s/it]\u001b[A\n",
      "48it [04:30,  5.45s/it]\u001b[A\n",
      "49it [04:36,  5.53s/it]\u001b[A\n",
      "50it [04:42,  5.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch    50  of    241. Elapsed: 0:04:42.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [04:47,  5.42s/it]\u001b[A\n",
      "52it [04:52,  5.44s/it]\u001b[A\n",
      "53it [04:57,  5.32s/it]\u001b[A\n",
      "54it [05:03,  5.52s/it]\u001b[A\n",
      "55it [05:09,  5.70s/it]\u001b[A\n",
      "56it [05:15,  5.80s/it]\u001b[A\n",
      "57it [05:21,  5.64s/it]\u001b[A\n",
      "58it [05:26,  5.62s/it]\u001b[A\n",
      "59it [05:32,  5.70s/it]\u001b[A\n",
      "60it [05:38,  5.67s/it]\u001b[A\n",
      "61it [05:44,  5.69s/it]\u001b[A\n",
      "62it [05:49,  5.54s/it]\u001b[A\n",
      "63it [05:54,  5.43s/it]\u001b[A\n",
      "64it [05:59,  5.37s/it]\u001b[A\n",
      "65it [06:05,  5.54s/it]\u001b[A\n",
      "66it [06:11,  5.58s/it]\u001b[A\n",
      "67it [06:16,  5.49s/it]\u001b[A\n",
      "68it [06:21,  5.47s/it]\u001b[A\n",
      "69it [06:27,  5.51s/it]\u001b[A\n",
      "70it [06:33,  5.55s/it]\u001b[A\n",
      "71it [06:38,  5.52s/it]\u001b[A\n",
      "72it [06:44,  5.49s/it]\u001b[A\n",
      "73it [06:49,  5.42s/it]\u001b[A\n",
      "74it [06:54,  5.41s/it]\u001b[A\n",
      "75it [06:59,  5.29s/it]\u001b[A\n",
      "76it [07:05,  5.47s/it]\u001b[A\n",
      "77it [07:11,  5.46s/it]\u001b[A\n",
      "78it [07:17,  5.68s/it]\u001b[A\n",
      "79it [07:22,  5.66s/it]\u001b[A\n",
      "80it [07:28,  5.78s/it]\u001b[A\n",
      "81it [07:35,  5.89s/it]\u001b[A\n",
      "82it [07:40,  5.70s/it]\u001b[A\n",
      "83it [07:45,  5.66s/it]\u001b[A\n",
      "84it [07:51,  5.53s/it]\u001b[A\n",
      "85it [07:56,  5.48s/it]\u001b[A\n",
      "86it [08:01,  5.42s/it]\u001b[A\n",
      "87it [08:07,  5.48s/it]\u001b[A\n",
      "88it [08:12,  5.34s/it]\u001b[A\n",
      "89it [08:17,  5.29s/it]\u001b[A\n",
      "90it [08:22,  5.27s/it]\u001b[A\n",
      "91it [08:28,  5.48s/it]\u001b[A\n",
      "92it [08:34,  5.65s/it]\u001b[A\n",
      "93it [08:40,  5.69s/it]\u001b[A\n",
      "94it [08:46,  5.62s/it]\u001b[A\n",
      "95it [08:51,  5.62s/it]\u001b[A\n",
      "96it [08:56,  5.50s/it]\u001b[A\n",
      "97it [09:02,  5.49s/it]\u001b[A\n",
      "98it [09:08,  5.54s/it]\u001b[A\n",
      "99it [09:13,  5.51s/it]\u001b[A\n",
      "100it [09:18,  5.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   100  of    241. Elapsed: 0:09:19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "101it [09:24,  5.43s/it]\u001b[A\n",
      "102it [09:29,  5.42s/it]\u001b[A\n",
      "103it [09:35,  5.56s/it]\u001b[A\n",
      "104it [09:40,  5.54s/it]\u001b[A\n",
      "105it [09:46,  5.56s/it]\u001b[A\n",
      "106it [09:51,  5.44s/it]\u001b[A\n",
      "107it [09:56,  5.38s/it]\u001b[A\n",
      "108it [10:02,  5.51s/it]\u001b[A\n",
      "109it [10:08,  5.55s/it]\u001b[A\n",
      "110it [10:13,  5.52s/it]\u001b[A\n",
      "111it [10:19,  5.45s/it]\u001b[A\n",
      "112it [10:24,  5.50s/it]\u001b[A\n",
      "113it [10:30,  5.49s/it]\u001b[A\n",
      "114it [10:36,  5.63s/it]\u001b[A\n",
      "115it [10:41,  5.66s/it]\u001b[A\n",
      "116it [10:47,  5.60s/it]\u001b[A\n",
      "117it [10:52,  5.51s/it]\u001b[A\n",
      "118it [10:57,  5.45s/it]\u001b[A\n",
      "119it [11:03,  5.53s/it]\u001b[A\n",
      "120it [11:09,  5.52s/it]\u001b[A\n",
      "121it [11:14,  5.51s/it]\u001b[A\n",
      "122it [11:19,  5.43s/it]\u001b[A\n",
      "123it [11:25,  5.41s/it]\u001b[A\n",
      "124it [11:30,  5.34s/it]\u001b[A\n",
      "125it [11:36,  5.50s/it]\u001b[A\n",
      "126it [11:41,  5.53s/it]\u001b[A\n",
      "127it [11:47,  5.54s/it]\u001b[A\n",
      "128it [11:52,  5.53s/it]\u001b[A\n",
      "129it [11:58,  5.64s/it]\u001b[A\n",
      "130it [12:05,  5.80s/it]\u001b[A\n",
      "131it [12:10,  5.71s/it]\u001b[A\n",
      "132it [12:15,  5.54s/it]\u001b[A\n",
      "133it [12:21,  5.48s/it]\u001b[A\n",
      "134it [12:26,  5.42s/it]\u001b[A\n",
      "135it [12:32,  5.79s/it]\u001b[A\n",
      "136it [12:38,  5.69s/it]\u001b[A\n",
      "137it [12:43,  5.58s/it]\u001b[A\n",
      "138it [12:49,  5.54s/it]\u001b[A\n",
      "139it [12:55,  5.71s/it]\u001b[A\n",
      "140it [13:00,  5.60s/it]\u001b[A\n",
      "141it [13:06,  5.66s/it]\u001b[A\n",
      "142it [13:11,  5.60s/it]\u001b[A\n",
      "143it [13:17,  5.46s/it]\u001b[A\n",
      "144it [13:22,  5.40s/it]\u001b[A\n",
      "145it [13:27,  5.47s/it]\u001b[A\n",
      "146it [13:33,  5.58s/it]\u001b[A\n",
      "147it [13:39,  5.55s/it]\u001b[A\n",
      "148it [13:44,  5.51s/it]\u001b[A\n",
      "149it [13:49,  5.44s/it]\u001b[A\n",
      "150it [13:55,  5.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   150  of    241. Elapsed: 0:13:55.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "151it [14:00,  5.26s/it]\u001b[A\n",
      "152it [14:05,  5.42s/it]\u001b[A\n",
      "153it [14:11,  5.39s/it]\u001b[A\n",
      "154it [14:16,  5.37s/it]\u001b[A\n",
      "155it [14:21,  5.34s/it]\u001b[A\n",
      "156it [14:27,  5.35s/it]\u001b[A\n",
      "157it [14:32,  5.41s/it]\u001b[A\n",
      "158it [14:37,  5.36s/it]\u001b[A\n",
      "159it [14:43,  5.42s/it]\u001b[A\n",
      "160it [14:49,  5.46s/it]\u001b[A\n",
      "161it [14:54,  5.51s/it]\u001b[A\n",
      "162it [15:00,  5.48s/it]\u001b[A\n",
      "163it [15:06,  5.59s/it]\u001b[A\n",
      "164it [15:11,  5.70s/it]\u001b[A\n",
      "165it [15:17,  5.67s/it]\u001b[A\n",
      "166it [15:22,  5.54s/it]\u001b[A\n",
      "167it [15:28,  5.54s/it]\u001b[A\n",
      "168it [15:34,  5.71s/it]\u001b[A\n",
      "169it [15:39,  5.55s/it]\u001b[A\n",
      "170it [15:45,  5.50s/it]\u001b[A\n",
      "171it [15:50,  5.43s/it]\u001b[A\n",
      "172it [15:55,  5.44s/it]\u001b[A\n",
      "173it [16:01,  5.67s/it]\u001b[A\n",
      "174it [16:07,  5.69s/it]\u001b[A\n",
      "175it [16:13,  5.59s/it]\u001b[A\n",
      "176it [16:18,  5.53s/it]\u001b[A\n",
      "177it [16:23,  5.50s/it]\u001b[A\n",
      "178it [16:29,  5.54s/it]\u001b[A\n",
      "179it [16:35,  5.67s/it]\u001b[A\n",
      "180it [16:40,  5.59s/it]\u001b[A\n",
      "181it [16:45,  5.44s/it]\u001b[A\n",
      "182it [16:52,  5.80s/it]\u001b[A\n",
      "183it [16:57,  5.67s/it]\u001b[A\n",
      "184it [17:03,  5.78s/it]\u001b[A\n",
      "185it [17:09,  5.71s/it]\u001b[A\n",
      "186it [17:14,  5.58s/it]\u001b[A\n",
      "187it [17:19,  5.46s/it]\u001b[A\n",
      "188it [17:25,  5.41s/it]\u001b[A\n",
      "189it [17:31,  5.56s/it]\u001b[A\n",
      "190it [17:37,  5.70s/it]\u001b[A\n",
      "191it [17:42,  5.63s/it]\u001b[A\n",
      "192it [17:48,  5.60s/it]\u001b[A\n",
      "193it [17:53,  5.47s/it]\u001b[A\n",
      "194it [17:58,  5.43s/it]\u001b[A\n",
      "195it [18:04,  5.66s/it]\u001b[A\n",
      "196it [18:10,  5.58s/it]\u001b[A\n",
      "197it [18:15,  5.53s/it]\u001b[A\n",
      "198it [18:21,  5.53s/it]\u001b[A\n",
      "199it [18:26,  5.46s/it]\u001b[A\n",
      "200it [18:32,  5.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   200  of    241. Elapsed: 0:18:32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "201it [18:37,  5.51s/it]\u001b[A\n",
      "202it [18:43,  5.52s/it]\u001b[A\n",
      "203it [18:48,  5.48s/it]\u001b[A\n",
      "204it [18:54,  5.50s/it]\u001b[A\n",
      "205it [18:59,  5.37s/it]\u001b[A\n",
      "206it [19:05,  5.56s/it]\u001b[A\n",
      "207it [19:10,  5.39s/it]\u001b[A\n",
      "208it [19:15,  5.30s/it]\u001b[A\n",
      "209it [19:20,  5.27s/it]\u001b[A\n",
      "210it [19:25,  5.31s/it]\u001b[A\n",
      "211it [19:31,  5.35s/it]\u001b[A\n",
      "212it [19:37,  5.49s/it]\u001b[A\n",
      "213it [19:42,  5.43s/it]\u001b[A\n",
      "214it [19:47,  5.38s/it]\u001b[A\n",
      "215it [19:53,  5.38s/it]\u001b[A\n",
      "216it [19:58,  5.32s/it]\u001b[A\n",
      "217it [20:03,  5.42s/it]\u001b[A\n",
      "218it [20:09,  5.40s/it]\u001b[A\n",
      "219it [20:14,  5.38s/it]\u001b[A\n",
      "220it [20:19,  5.30s/it]\u001b[A\n",
      "221it [20:25,  5.30s/it]\u001b[A\n",
      "222it [20:31,  5.57s/it]\u001b[A\n",
      "223it [20:36,  5.58s/it]\u001b[A\n",
      "224it [20:42,  5.57s/it]\u001b[A\n",
      "225it [20:47,  5.57s/it]\u001b[A\n",
      "226it [20:53,  5.54s/it]\u001b[A\n",
      "227it [20:58,  5.51s/it]\u001b[A\n",
      "228it [21:04,  5.67s/it]\u001b[A\n",
      "229it [21:10,  5.60s/it]\u001b[A\n",
      "230it [21:15,  5.53s/it]\u001b[A\n",
      "231it [21:20,  5.42s/it]\u001b[A\n",
      "232it [21:26,  5.38s/it]\u001b[A\n",
      "233it [21:31,  5.44s/it]\u001b[A\n",
      "234it [21:37,  5.48s/it]\u001b[A\n",
      "235it [21:42,  5.50s/it]\u001b[A\n",
      "236it [21:48,  5.44s/it]\u001b[A\n",
      "237it [21:53,  5.37s/it]\u001b[A\n",
      "238it [21:58,  5.36s/it]\u001b[A\n",
      "239it [22:04,  5.48s/it]\u001b[A\n",
      "240it [22:09,  5.47s/it]\u001b[A\n",
      "241it [22:12,  5.53s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training loss: 0.31\n",
      "Training epoch took: 0:22:13\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 1/27 [00:01<00:37,  1.45s/it]\u001b[A\n",
      "  7%|▋         | 2/27 [00:02<00:36,  1.44s/it]\u001b[A\n",
      " 11%|█         | 3/27 [00:04<00:34,  1.45s/it]\u001b[A\n",
      " 15%|█▍        | 4/27 [00:05<00:34,  1.51s/it]\u001b[A\n",
      " 19%|█▊        | 5/27 [00:07<00:35,  1.60s/it]\u001b[A\n",
      " 22%|██▏       | 6/27 [00:09<00:34,  1.65s/it]\u001b[A\n",
      " 26%|██▌       | 7/27 [00:11<00:32,  1.64s/it]\u001b[A\n",
      " 30%|██▉       | 8/27 [00:12<00:30,  1.61s/it]\u001b[A\n",
      " 33%|███▎      | 9/27 [00:14<00:29,  1.63s/it]\u001b[A\n",
      " 37%|███▋      | 10/27 [00:16<00:29,  1.71s/it]\u001b[A\n",
      " 41%|████      | 11/27 [00:17<00:27,  1.71s/it]\u001b[A\n",
      " 44%|████▍     | 12/27 [00:19<00:26,  1.75s/it]\u001b[A\n",
      " 48%|████▊     | 13/27 [00:21<00:24,  1.76s/it]\u001b[A\n",
      " 52%|█████▏    | 14/27 [00:23<00:22,  1.70s/it]\u001b[A\n",
      " 56%|█████▌    | 15/27 [00:24<00:20,  1.69s/it]\u001b[A\n",
      " 59%|█████▉    | 16/27 [00:26<00:18,  1.69s/it]\u001b[A\n",
      " 63%|██████▎   | 17/27 [00:28<00:16,  1.70s/it]\u001b[A\n",
      " 67%|██████▋   | 18/27 [00:29<00:14,  1.64s/it]\u001b[A\n",
      " 70%|███████   | 19/27 [00:31<00:13,  1.66s/it]\u001b[A\n",
      " 74%|███████▍  | 20/27 [00:33<00:11,  1.67s/it]\u001b[A\n",
      " 78%|███████▊  | 21/27 [00:34<00:10,  1.69s/it]\u001b[A\n",
      " 81%|████████▏ | 22/27 [00:36<00:08,  1.71s/it]\u001b[A\n",
      " 85%|████████▌ | 23/27 [00:38<00:06,  1.68s/it]\u001b[A\n",
      " 89%|████████▉ | 24/27 [00:39<00:04,  1.66s/it]\u001b[A\n",
      " 93%|█████████▎| 25/27 [00:41<00:03,  1.62s/it]\u001b[A\n",
      " 96%|█████████▋| 26/27 [00:42<00:01,  1.57s/it]\u001b[A\n",
      "100%|██████████| 27/27 [00:44<00:00,  1.63s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [45:47<22:54, 1374.13s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Validation Loss: 0.42\n",
      "Validation took: 0:00:44\n",
      "======= Epoch 3 / 3 =======\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:05,  5.78s/it]\u001b[A\n",
      "2it [00:11,  5.67s/it]\u001b[A\n",
      "3it [00:16,  5.56s/it]\u001b[A\n",
      "4it [00:22,  5.50s/it]\u001b[A\n",
      "5it [00:27,  5.42s/it]\u001b[A\n",
      "6it [00:32,  5.43s/it]\u001b[A\n",
      "7it [00:38,  5.55s/it]\u001b[A\n",
      "8it [00:44,  5.54s/it]\u001b[A\n",
      "9it [00:49,  5.44s/it]\u001b[A\n",
      "10it [00:54,  5.31s/it]\u001b[A\n",
      "11it [00:59,  5.36s/it]\u001b[A\n",
      "12it [01:05,  5.33s/it]\u001b[A\n",
      "13it [01:11,  5.46s/it]\u001b[A\n",
      "14it [01:16,  5.39s/it]\u001b[A\n",
      "15it [01:21,  5.43s/it]\u001b[A\n",
      "16it [01:27,  5.40s/it]\u001b[A\n",
      "17it [01:32,  5.44s/it]\u001b[A\n",
      "18it [01:38,  5.70s/it]\u001b[A\n",
      "19it [01:44,  5.61s/it]\u001b[A\n",
      "20it [01:49,  5.50s/it]\u001b[A\n",
      "21it [01:54,  5.46s/it]\u001b[A\n",
      "22it [02:00,  5.41s/it]\u001b[A\n",
      "23it [02:05,  5.44s/it]\u001b[A\n",
      "24it [02:11,  5.43s/it]\u001b[A\n",
      "25it [02:16,  5.32s/it]\u001b[A\n",
      "26it [02:21,  5.27s/it]\u001b[A\n",
      "27it [02:26,  5.31s/it]\u001b[A\n",
      "28it [02:32,  5.35s/it]\u001b[A\n",
      "29it [02:37,  5.47s/it]\u001b[A\n",
      "30it [02:43,  5.45s/it]\u001b[A\n",
      "31it [02:48,  5.40s/it]\u001b[A\n",
      "32it [02:53,  5.35s/it]\u001b[A\n",
      "33it [02:59,  5.34s/it]\u001b[A\n",
      "34it [03:04,  5.39s/it]\u001b[A\n",
      "35it [03:10,  5.47s/it]\u001b[A\n",
      "36it [03:15,  5.32s/it]\u001b[A\n",
      "37it [03:20,  5.34s/it]\u001b[A\n",
      "38it [03:26,  5.34s/it]\u001b[A\n",
      "39it [03:31,  5.35s/it]\u001b[A\n",
      "40it [03:37,  5.61s/it]\u001b[A\n",
      "41it [03:43,  5.60s/it]\u001b[A\n",
      "42it [03:48,  5.54s/it]\u001b[A\n",
      "43it [03:53,  5.49s/it]\u001b[A\n",
      "44it [03:59,  5.49s/it]\u001b[A\n",
      "45it [04:05,  5.66s/it]\u001b[A\n",
      "46it [04:10,  5.60s/it]\u001b[A\n",
      "47it [04:16,  5.53s/it]\u001b[A\n",
      "48it [04:21,  5.40s/it]\u001b[A\n",
      "49it [04:26,  5.36s/it]\u001b[A\n",
      "50it [04:33,  5.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch    50  of    241. Elapsed: 0:04:33.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [04:39,  5.77s/it]\u001b[A\n",
      "52it [04:44,  5.63s/it]\u001b[A\n",
      "53it [04:50,  5.62s/it]\u001b[A\n",
      "54it [04:55,  5.49s/it]\u001b[A\n",
      "55it [05:00,  5.45s/it]\u001b[A\n",
      "56it [05:06,  5.47s/it]\u001b[A\n",
      "57it [05:12,  5.65s/it]\u001b[A\n",
      "58it [05:18,  5.73s/it]\u001b[A\n",
      "59it [05:23,  5.76s/it]\u001b[A\n",
      "60it [05:29,  5.85s/it]\u001b[A\n",
      "61it [05:35,  5.86s/it]\u001b[A\n",
      "62it [05:41,  5.73s/it]\u001b[A\n",
      "63it [05:46,  5.63s/it]\u001b[A\n",
      "64it [05:51,  5.52s/it]\u001b[A\n",
      "65it [05:57,  5.45s/it]\u001b[A\n",
      "66it [06:02,  5.36s/it]\u001b[A\n",
      "67it [06:08,  5.66s/it]\u001b[A\n",
      "68it [06:15,  5.85s/it]\u001b[A\n",
      "69it [06:20,  5.72s/it]\u001b[A\n",
      "70it [06:26,  5.87s/it]\u001b[A\n",
      "71it [06:32,  5.83s/it]\u001b[A\n",
      "72it [06:38,  5.87s/it]\u001b[A\n",
      "73it [06:43,  5.71s/it]\u001b[A\n",
      "74it [06:48,  5.58s/it]\u001b[A\n",
      "75it [06:54,  5.71s/it]\u001b[A\n",
      "76it [07:00,  5.76s/it]\u001b[A\n",
      "77it [07:06,  5.79s/it]\u001b[A\n",
      "78it [07:12,  5.68s/it]\u001b[A\n",
      "79it [07:17,  5.56s/it]\u001b[A\n",
      "80it [07:22,  5.47s/it]\u001b[A\n",
      "81it [07:27,  5.42s/it]\u001b[A\n",
      "82it [07:33,  5.44s/it]\u001b[A\n",
      "83it [07:39,  5.55s/it]\u001b[A\n",
      "84it [07:44,  5.57s/it]\u001b[A\n",
      "85it [07:50,  5.49s/it]\u001b[A\n",
      "86it [07:55,  5.52s/it]\u001b[A\n",
      "87it [08:00,  5.43s/it]\u001b[A\n",
      "88it [08:06,  5.61s/it]\u001b[A\n",
      "89it [08:12,  5.53s/it]\u001b[A\n",
      "90it [08:17,  5.49s/it]\u001b[A\n",
      "91it [08:23,  5.43s/it]\u001b[A\n",
      "92it [08:28,  5.43s/it]\u001b[A\n",
      "93it [08:33,  5.38s/it]\u001b[A\n",
      "94it [08:39,  5.51s/it]\u001b[A\n",
      "95it [08:44,  5.43s/it]\u001b[A\n",
      "96it [08:49,  5.33s/it]\u001b[A\n",
      "97it [08:55,  5.34s/it]\u001b[A\n",
      "98it [09:00,  5.31s/it]\u001b[A\n",
      "99it [09:06,  5.44s/it]\u001b[A\n",
      "100it [09:11,  5.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   100  of    241. Elapsed: 0:09:12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "101it [09:17,  5.45s/it]\u001b[A\n",
      "102it [09:22,  5.39s/it]\u001b[A\n",
      "103it [09:27,  5.40s/it]\u001b[A\n",
      "104it [09:33,  5.63s/it]\u001b[A\n",
      "105it [09:39,  5.72s/it]\u001b[A\n",
      "106it [09:45,  5.65s/it]\u001b[A\n",
      "107it [09:50,  5.57s/it]\u001b[A\n",
      "108it [09:56,  5.49s/it]\u001b[A\n",
      "109it [10:01,  5.39s/it]\u001b[A\n",
      "110it [10:07,  5.61s/it]\u001b[A\n",
      "111it [10:12,  5.56s/it]\u001b[A\n",
      "112it [10:17,  5.44s/it]\u001b[A\n",
      "113it [10:23,  5.40s/it]\u001b[A\n",
      "114it [10:28,  5.39s/it]\u001b[A\n",
      "115it [10:34,  5.44s/it]\u001b[A\n",
      "116it [10:39,  5.54s/it]\u001b[A\n",
      "117it [10:45,  5.43s/it]\u001b[A\n",
      "118it [10:50,  5.43s/it]\u001b[A\n",
      "119it [10:56,  5.48s/it]\u001b[A\n",
      "120it [11:01,  5.39s/it]\u001b[A\n",
      "121it [11:07,  5.56s/it]\u001b[A\n",
      "122it [11:12,  5.53s/it]\u001b[A\n",
      "123it [11:18,  5.53s/it]\u001b[A\n",
      "124it [11:23,  5.50s/it]\u001b[A\n",
      "125it [11:29,  5.47s/it]\u001b[A\n",
      "126it [11:34,  5.46s/it]\u001b[A\n",
      "127it [11:40,  5.58s/it]\u001b[A\n",
      "128it [11:46,  5.67s/it]\u001b[A\n",
      "129it [11:51,  5.67s/it]\u001b[A\n",
      "130it [11:57,  5.56s/it]\u001b[A\n",
      "131it [12:02,  5.49s/it]\u001b[A\n",
      "132it [12:08,  5.61s/it]\u001b[A\n",
      "133it [12:13,  5.50s/it]\u001b[A\n",
      "134it [12:19,  5.45s/it]\u001b[A\n",
      "135it [12:24,  5.48s/it]\u001b[A\n",
      "136it [12:29,  5.42s/it]\u001b[A\n",
      "137it [12:35,  5.47s/it]\u001b[A\n",
      "138it [12:40,  5.46s/it]\u001b[A\n",
      "139it [12:46,  5.56s/it]\u001b[A\n",
      "140it [12:52,  5.71s/it]\u001b[A\n",
      "141it [12:58,  5.77s/it]\u001b[A\n",
      "142it [13:03,  5.64s/it]\u001b[A\n",
      "143it [13:09,  5.74s/it]\u001b[A\n",
      "144it [13:15,  5.60s/it]\u001b[A\n",
      "145it [13:20,  5.43s/it]\u001b[A\n",
      "146it [13:25,  5.34s/it]\u001b[A\n",
      "147it [13:31,  5.43s/it]\u001b[A\n",
      "148it [13:36,  5.60s/it]\u001b[A\n",
      "149it [13:42,  5.67s/it]\u001b[A\n",
      "150it [13:48,  5.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   150  of    241. Elapsed: 0:13:49.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "151it [13:54,  5.68s/it]\u001b[A\n",
      "152it [13:59,  5.64s/it]\u001b[A\n",
      "153it [14:06,  5.88s/it]\u001b[A\n",
      "154it [14:12,  5.95s/it]\u001b[A\n",
      "155it [14:17,  5.81s/it]\u001b[A\n",
      "156it [14:23,  5.61s/it]\u001b[A\n",
      "157it [14:28,  5.53s/it]\u001b[A\n",
      "158it [14:34,  5.60s/it]\u001b[A\n",
      "159it [14:40,  5.69s/it]\u001b[A\n",
      "160it [14:45,  5.52s/it]\u001b[A\n",
      "161it [14:50,  5.51s/it]\u001b[A\n",
      "162it [14:56,  5.51s/it]\u001b[A\n",
      "163it [15:01,  5.49s/it]\u001b[A\n",
      "164it [15:07,  5.61s/it]\u001b[A\n",
      "165it [15:13,  5.63s/it]\u001b[A\n",
      "166it [15:18,  5.57s/it]\u001b[A\n",
      "167it [15:24,  5.53s/it]\u001b[A\n",
      "168it [15:29,  5.43s/it]\u001b[A\n",
      "169it [15:34,  5.46s/it]\u001b[A\n",
      "170it [15:40,  5.52s/it]\u001b[A\n",
      "171it [15:45,  5.42s/it]\u001b[A\n",
      "172it [15:51,  5.50s/it]\u001b[A\n",
      "173it [15:56,  5.52s/it]\u001b[A\n",
      "174it [16:02,  5.56s/it]\u001b[A\n",
      "175it [16:08,  5.65s/it]\u001b[A\n",
      "176it [16:13,  5.65s/it]\u001b[A\n",
      "177it [16:19,  5.48s/it]\u001b[A\n",
      "178it [16:24,  5.37s/it]\u001b[A\n",
      "179it [16:29,  5.40s/it]\u001b[A\n",
      "180it [16:35,  5.49s/it]\u001b[A\n",
      "181it [16:41,  5.61s/it]\u001b[A\n",
      "182it [16:46,  5.59s/it]\u001b[A\n",
      "183it [16:52,  5.51s/it]\u001b[A\n",
      "184it [16:57,  5.54s/it]\u001b[A\n",
      "185it [17:03,  5.68s/it]\u001b[A\n",
      "186it [17:09,  5.71s/it]\u001b[A\n",
      "187it [17:15,  5.65s/it]\u001b[A\n",
      "188it [17:20,  5.48s/it]\u001b[A\n",
      "189it [17:25,  5.56s/it]\u001b[A\n",
      "190it [17:31,  5.58s/it]\u001b[A\n",
      "191it [17:37,  5.78s/it]\u001b[A\n",
      "192it [17:43,  5.72s/it]\u001b[A\n",
      "193it [17:48,  5.59s/it]\u001b[A\n",
      "194it [17:54,  5.57s/it]\u001b[A\n",
      "195it [17:59,  5.51s/it]\u001b[A\n",
      "196it [18:04,  5.46s/it]\u001b[A\n",
      "197it [18:10,  5.47s/it]\u001b[A\n",
      "198it [18:15,  5.41s/it]\u001b[A\n",
      "199it [18:21,  5.41s/it]\u001b[A\n",
      "200it [18:26,  5.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch   200  of    241. Elapsed: 0:18:26.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "201it [18:31,  5.31s/it]\u001b[A\n",
      "202it [18:37,  5.58s/it]\u001b[A\n",
      "203it [18:43,  5.51s/it]\u001b[A\n",
      "204it [18:48,  5.48s/it]\u001b[A\n",
      "205it [18:53,  5.37s/it]\u001b[A\n",
      "206it [18:58,  5.33s/it]\u001b[A\n",
      "207it [19:04,  5.39s/it]\u001b[A\n",
      "208it [19:09,  5.48s/it]\u001b[A\n",
      "209it [19:15,  5.35s/it]\u001b[A\n",
      "210it [19:20,  5.32s/it]\u001b[A\n",
      "211it [19:25,  5.27s/it]\u001b[A\n",
      "212it [19:31,  5.37s/it]\u001b[A\n",
      "213it [19:37,  5.61s/it]\u001b[A\n",
      "214it [19:42,  5.56s/it]\u001b[A\n",
      "215it [19:48,  5.60s/it]\u001b[A\n",
      "216it [19:53,  5.49s/it]\u001b[A\n",
      "217it [19:58,  5.38s/it]\u001b[A\n",
      "218it [20:03,  5.31s/it]\u001b[A\n",
      "219it [20:09,  5.44s/it]\u001b[A\n",
      "220it [20:15,  5.45s/it]\u001b[A\n",
      "221it [20:20,  5.37s/it]\u001b[A\n",
      "222it [20:25,  5.39s/it]\u001b[A\n",
      "223it [20:30,  5.31s/it]\u001b[A\n",
      "224it [20:36,  5.50s/it]\u001b[A\n",
      "225it [20:42,  5.60s/it]\u001b[A\n",
      "226it [20:47,  5.51s/it]\u001b[A\n",
      "227it [20:53,  5.39s/it]\u001b[A\n",
      "228it [20:58,  5.43s/it]\u001b[A\n",
      "229it [21:04,  5.48s/it]\u001b[A\n",
      "230it [21:09,  5.57s/it]\u001b[A\n",
      "231it [21:15,  5.52s/it]\u001b[A\n",
      "232it [21:20,  5.41s/it]\u001b[A\n",
      "233it [21:25,  5.39s/it]\u001b[A\n",
      "234it [21:31,  5.41s/it]\u001b[A\n",
      "235it [21:37,  5.65s/it]\u001b[A\n",
      "236it [21:42,  5.61s/it]\u001b[A\n",
      "237it [21:48,  5.52s/it]\u001b[A\n",
      "238it [21:53,  5.42s/it]\u001b[A\n",
      "239it [21:58,  5.38s/it]\u001b[A\n",
      "240it [22:04,  5.45s/it]\u001b[A\n",
      "241it [22:07,  5.51s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training loss: 0.21\n",
      "Training epoch took: 0:22:08\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 1/27 [00:01<00:44,  1.71s/it]\u001b[A\n",
      "  7%|▋         | 2/27 [00:03<00:42,  1.71s/it]\u001b[A\n",
      " 11%|█         | 3/27 [00:05<00:40,  1.70s/it]\u001b[A\n",
      " 15%|█▍        | 4/27 [00:06<00:39,  1.71s/it]\u001b[A\n",
      " 19%|█▊        | 5/27 [00:08<00:37,  1.70s/it]\u001b[A\n",
      " 22%|██▏       | 6/27 [00:10<00:35,  1.71s/it]\u001b[A\n",
      " 26%|██▌       | 7/27 [00:11<00:33,  1.67s/it]\u001b[A\n",
      " 30%|██▉       | 8/27 [00:13<00:30,  1.58s/it]\u001b[A\n",
      " 33%|███▎      | 9/27 [00:14<00:27,  1.54s/it]\u001b[A\n",
      " 37%|███▋      | 10/27 [00:16<00:26,  1.58s/it]\u001b[A\n",
      " 41%|████      | 11/27 [00:17<00:24,  1.53s/it]\u001b[A\n",
      " 44%|████▍     | 12/27 [00:19<00:23,  1.54s/it]\u001b[A\n",
      " 48%|████▊     | 13/27 [00:21<00:22,  1.60s/it]\u001b[A\n",
      " 52%|█████▏    | 14/27 [00:22<00:21,  1.64s/it]\u001b[A\n",
      " 56%|█████▌    | 15/27 [00:24<00:19,  1.66s/it]\u001b[A\n",
      " 59%|█████▉    | 16/27 [00:26<00:18,  1.67s/it]\u001b[A\n",
      " 63%|██████▎   | 17/27 [00:28<00:17,  1.72s/it]\u001b[A\n",
      " 67%|██████▋   | 18/27 [00:29<00:15,  1.76s/it]\u001b[A\n",
      " 70%|███████   | 19/27 [00:31<00:13,  1.74s/it]\u001b[A\n",
      " 74%|███████▍  | 20/27 [00:33<00:12,  1.73s/it]\u001b[A\n",
      " 78%|███████▊  | 21/27 [00:34<00:10,  1.72s/it]\u001b[A\n",
      " 81%|████████▏ | 22/27 [00:36<00:08,  1.72s/it]\u001b[A\n",
      " 85%|████████▌ | 23/27 [00:38<00:06,  1.72s/it]\u001b[A\n",
      " 89%|████████▉ | 24/27 [00:40<00:05,  1.70s/it]\u001b[A\n",
      " 93%|█████████▎| 25/27 [00:41<00:03,  1.67s/it]\u001b[A\n",
      " 96%|█████████▋| 26/27 [00:43<00:01,  1.68s/it]\u001b[A\n",
      "100%|██████████| 27/27 [00:44<00:00,  1.65s/it]\u001b[A\n",
      "100%|██████████| 3/3 [1:08:39<00:00, 1373.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Validation Loss: 0.41\n",
      "Validation took: 0:00:45\n",
      "Training complete!\n",
      "Total training took 1:08:40 (h:mm:ss)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Based on the `run_glue.py`\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 950916\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in tqdm(range(0, epochs)):\n",
    "    print('======= Epoch {:} / {:} ======='.format(epoch_i+1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "        # Update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)            \n",
    "            print('Batch {:>5,}  of  {:>5,}. Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)                \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in tqdm(validation_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'Epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Validation Loss': avg_val_loss,\n",
    "            'Validation Accuracy': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a938ccb9",
   "metadata": {},
   "source": [
    "## Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "624f1985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T10:21:58.470247Z",
     "start_time": "2022-01-16T10:21:58.228712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 516\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, \n",
    "                 names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                     \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,          \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt'    \n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fd7d9f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T10:23:11.932335Z",
     "start_time": "2022-01-16T10:22:44.990437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 516 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c34ec79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T11:41:45.318406Z",
     "start_time": "2022-01-16T11:41:45.313610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 354 of 516 (68.60%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "609cd5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T11:42:33.575846Z",
     "start_time": "2022-01-16T11:42:31.914467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "for i in range(len(true_labels)):\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4849e04f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T12:07:49.788452Z",
     "start_time": "2022-01-16T12:07:49.563743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the MCC score for each batch of test samples.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "380fea5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T12:09:13.964902Z",
     "start_time": "2022-01-16T12:09:13.955725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.540\n"
     ]
    }
   ],
   "source": [
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6111816",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41c328ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T12:10:18.437507Z",
     "start_time": "2022-01-16T12:10:17.899382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_bert/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_bert/tokenizer_config.json',\n",
       " './model_bert/special_tokens_map.json',\n",
       " './model_bert/vocab.txt',\n",
       " './model_bert/added_tokens.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_bert/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762df61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
